{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sessions\n",
    "- each session is a different dataset\n",
    "- folders inside each session: responses, poses and trials\n",
    "- trials is not a modality, it's just for me to keep track of information when evaluating the model\n",
    "\n",
    "### poses\n",
    "- `data.mem`: $(x, y, z)$ coordinates of each joint for the full session. shape: `(n_frames, 3*n_joints)`\n",
    "- `meta.yml`: dictionary with metadata, see `metadata` below\n",
    "- `meta/com.npy`: $(x, y, z)$ coordinate of the center of mass (com) for the full session. shape: `(n_frames, 3)`\n",
    "- `meta/joints.npy`: name of the joints tracked\n",
    "- `meta/skeleton.npy`: adjacency list for all the joints\n",
    "\n",
    "### responses\n",
    "- `data.mem`: timing of each spike of each neuron for the full session. shape: `(n_frames, n_neurons)`\n",
    "- `meta.yml`: dictionary with metadata, see `metadata` below\n",
    "- `meta/areas.npy`: array with the brain areas\n",
    "- `meta/bad_channels.npy`: array with the indices of the bad channels\n",
    "\n",
    "### metadata (meta.yml files)\n",
    "- `dtype`: necessary to load `.mem` files\n",
    "- `is_mem_mapped`: if it's `.mem` or `.npy`\n",
    "- `modality`: sequence or trial\n",
    "- `n_signals`: number of joints, neurons etc\n",
    "- `n_timestamps`: number of frames \n",
    "- `phase_shift_per_signal`: useless for me, always false\n",
    "- `sampling_rate`: 100 for poses, 1000 for responses, target and trials\n",
    "- `start_time`: 0 in my case, i think\n",
    "\n",
    "### trials\n",
    "- trial_start: when each trial starts\n",
    "- trial_end: when each trial ends\n",
    "\n",
    "### to keep in mind\n",
    "- test trials\n",
    "    - bex_20230226: 1\n",
    "    - jon_20230203: 1\n",
    "    - luk_20230126: 0\n",
    "- validation trials\n",
    "    - bex_20230226: 2\n",
    "    - jon_20230126: 0\n",
    "    - luk_20230202: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(Path().resolve().parent)\n",
    "\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_kps2idx = [0, 1, 8, 13, 18, 23, 28]\n",
    "\n",
    "keypoints = [\n",
    "    \"neck\",\n",
    "    \"spine\",\n",
    "    \"head\",\n",
    "    \"L_ear\",\n",
    "    \"R_ear\",\n",
    "    \"L_eye\",\n",
    "    \"R_eye\",\n",
    "    \"nose\",\n",
    "    \"L_shoulder\",\n",
    "    \"L_elbow\",\n",
    "    \"L_wrist\",\n",
    "    \"L_upperArm\",\n",
    "    \"L_lowerArm\",\n",
    "    \"R_shoulder\",\n",
    "    \"R_elbow\",\n",
    "    \"R_wrist\",\n",
    "    \"R_upperArm\",\n",
    "    \"R_lowerArm\",\n",
    "    \"L_hip\",\n",
    "    \"L_knee\",\n",
    "    \"L_ankle\",\n",
    "    \"L_upperLeg\",\n",
    "    \"L_lowerLeg\",\n",
    "    \"R_hip\",\n",
    "    \"R_knee\",\n",
    "    \"R_ankle\",\n",
    "    \"R_upperLeg\",\n",
    "    \"R_lowerLeg\",\n",
    "    \"S_tail\",\n",
    "    \"M_tail\",\n",
    "    \"E_tail\",\n",
    "]\n",
    "\n",
    "skeleton = [\n",
    "    [0, 1],\n",
    "    [0, 2],\n",
    "    [0, 3],\n",
    "    [0, 4],\n",
    "    [0, 7],\n",
    "    [0, 8],\n",
    "    [0, 13],\n",
    "    [2, 3],\n",
    "    [2, 4],\n",
    "    [2, 5],\n",
    "    [2, 6],\n",
    "    [7, 3],\n",
    "    [7, 4],\n",
    "    [7, 5],\n",
    "    [7, 6],\n",
    "    [11, 8],\n",
    "    [11, 9],\n",
    "    [12, 9],\n",
    "    [12, 10],\n",
    "    [16, 13],\n",
    "    [16, 14],\n",
    "    [17, 14],\n",
    "    [17, 15],\n",
    "    [21, 18],\n",
    "    [21, 19],\n",
    "    [22, 19],\n",
    "    [22, 20],\n",
    "    [26, 23],\n",
    "    [26, 24],\n",
    "    [27, 24],\n",
    "    [27, 25],\n",
    "    [28, 1],\n",
    "    [28, 18],\n",
    "    [28, 23],\n",
    "    [29, 28],\n",
    "    [29, 30],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trials(filename):\n",
    "    TRIALS_DIR = os.path.join(filename, \"trials\")\n",
    "    os.makedirs(TRIALS_DIR, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(filename, \"meta.yml\"), \"r\") as f:\n",
    "        meta = yaml.safe_load(f)\n",
    "\n",
    "    test_trials = {\n",
    "        \"bex_20230226\": [1],\n",
    "        \"jon_20230203\": [1],\n",
    "        \"luk_20230126\": [0],\n",
    "    }\n",
    "    valid_trials = {\n",
    "        \"bex_20230226\": [2],\n",
    "        \"jon_20230126\": [0],\n",
    "        \"luk_20230202\": [1],\n",
    "    }\n",
    "    union_trials = {\n",
    "        key: valid_trials.get(key, []) + test_trials.get(key, [])\n",
    "        for key in set(valid_trials) | set(test_trials)\n",
    "    }\n",
    "    train_trials = {\n",
    "        filename: (\n",
    "            list(range(len(meta[\"trials\"])))\n",
    "            if filename not in union_trials\n",
    "            else [\n",
    "                i\n",
    "                for i in range(len(meta[\"trials\"]))\n",
    "                if filename in union_trials and i not in union_trials[filename]\n",
    "            ]\n",
    "        )\n",
    "    }\n",
    "    tiers = {\n",
    "        \"train\": train_trials[filename],\n",
    "        \"validation\": valid_trials.get(filename, []),\n",
    "        \"test\": test_trials.get(filename, []),\n",
    "    }\n",
    "    trials_start = [10 * trial[0] for trial in meta[\"trials\"]]\n",
    "    trials_end = [10 * trial[1] for trial in meta[\"trials\"]]\n",
    "\n",
    "    for tier in tiers:\n",
    "        for idx in tiers[tier]:\n",
    "            with open(os.path.join(TRIALS_DIR, f\"{idx}.yml\"), \"w\") as f:\n",
    "                data = {\n",
    "                    \"first_frame_idx\": trials_start[idx],\n",
    "                    \"num_frames\": (trials_end[idx] - trials_start[idx]),\n",
    "                    \"tier\": tier,\n",
    "                    \"trial_idx\": idx,\n",
    "                }\n",
    "                yaml.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_responses(filename):\n",
    "    RESP_DIR = os.path.join(filename, \"responses\")\n",
    "    os.makedirs(RESP_DIR, exist_ok=True)\n",
    "\n",
    "    MRESP_DIR = os.path.join(RESP_DIR, \"meta\")\n",
    "    os.makedirs(MRESP_DIR, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(filename, \"meta.yml\"), \"r\") as f:\n",
    "        meta = yaml.safe_load(f)\n",
    "\n",
    "    SPIKES_DIR = os.path.join(filename, \"spikes\")\n",
    "    spikes = np.zeros((10 * meta[\"total_n_frames\"], meta[\"n_channels\"]))\n",
    "    files = [\n",
    "        os.path.join(SPIKES_DIR, f\"spiketimes_ch{i + 1}.txt\")\n",
    "        for i in range(meta[\"n_channels\"])\n",
    "    ]\n",
    "\n",
    "    for i, fn in enumerate(files):\n",
    "        with open(fn, \"r\") as f:\n",
    "            fcsv = csv.reader(f, delimiter=\",\")\n",
    "            spiketimes = np.array(next(fcsv)).astype(float)\n",
    "            spiketimes = spiketimes[\n",
    "                (0 < spiketimes) & (spiketimes < 10 * meta[\"total_n_frames\"])\n",
    "            ].astype(int)\n",
    "            spikes[spiketimes, i] = 1\n",
    "\n",
    "    mmap = np.memmap(\n",
    "        os.path.join(RESP_DIR, \"data.mem\"),\n",
    "        dtype=\"float64\",\n",
    "        mode=\"w+\",\n",
    "        shape=spikes.shape,\n",
    "    )\n",
    "    mmap[:] = spikes\n",
    "    mmap.flush()\n",
    "\n",
    "    with open(os.path.join(RESP_DIR, \"meta.yml\"), \"w\") as f:\n",
    "        meta_resp = {\n",
    "            \"dtype\": \"float64\",\n",
    "            \"end_time\": len(spikes),\n",
    "            \"is_mem_mapped\": True,\n",
    "            \"modality\": \"sequence\",\n",
    "            \"n_signals\": spikes.shape[-1],\n",
    "            \"n_timestamps\": len(spikes),\n",
    "            \"phase_shift_per_signal\": False,\n",
    "            \"sampling_rate\": 1000,\n",
    "            \"start_time\": 0,\n",
    "        }\n",
    "        yaml.dump(meta_resp, f)\n",
    "\n",
    "    with open(os.path.join(MRESP_DIR, \"areas.npy\"), \"wb\") as f:\n",
    "        areas = np.empty(meta[\"n_channels\"], dtype=\"<U3\")\n",
    "        for area, ranges in meta[\"areas\"].items():\n",
    "            for start, end in ranges:\n",
    "                areas[start:end] = area\n",
    "        np.save(f, areas)\n",
    "\n",
    "    with open(os.path.join(MRESP_DIR, \"bad_channels.npy\"), \"wb\") as f:\n",
    "        # bad channels are 1-indexed\n",
    "        np.save(f, np.array(meta[\"bad_channels\"]) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_poses(filename):\n",
    "    POSES_DIR = os.path.join(filename, \"poses\")\n",
    "    os.makedirs(POSES_DIR, exist_ok=True)\n",
    "\n",
    "    MPOSES_DIR = os.path.join(POSES_DIR, \"meta\")\n",
    "    os.makedirs(MPOSES_DIR, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(filename, \"meta.yml\"), \"r\") as f:\n",
    "        meta = yaml.safe_load(f)\n",
    "\n",
    "    KEYPOINTS_DIR = os.path.join(filename, \"keypoints\")\n",
    "    files = [\n",
    "        os.path.join(KEYPOINTS_DIR, f)\n",
    "        for f in (\"x_coords.txt\", \"y_coords.txt\", \"z_coords.txt\")\n",
    "    ]\n",
    "    coords = []\n",
    "\n",
    "    for fn in files:\n",
    "        with open(fn, \"r\") as f:\n",
    "            fcsv = csv.reader(f, delimiter=\",\")\n",
    "            coords.append([np.array(row).astype(float) for row in fcsv])\n",
    "\n",
    "    coords = np.vstack(coords)\n",
    "    coords = np.reshape(coords, (-1, 3 * meta[\"n_keypoints\"]), \"F\")\n",
    "    mmap = np.memmap(\n",
    "        os.path.join(POSES_DIR, \"data.mem\"),\n",
    "        dtype=\"float64\",\n",
    "        mode=\"w+\",\n",
    "        shape=coords.shape,\n",
    "    )\n",
    "    mmap[:] = coords\n",
    "    mmap.flush()\n",
    "\n",
    "    with open(os.path.join(POSES_DIR, \"meta.yml\"), \"w\") as f:\n",
    "        meta_resp = {\n",
    "            \"dtype\": \"float64\",\n",
    "            \"end_time\": len(coords),\n",
    "            \"is_mem_mapped\": True,\n",
    "            \"modality\": \"sequence\",\n",
    "            \"n_signals\": coords.shape[-1],\n",
    "            \"n_timestamps\": len(coords),\n",
    "            \"phase_shift_per_signal\": False,\n",
    "            \"sampling_rate\": 100,\n",
    "            \"start_time\": 0,\n",
    "        }\n",
    "        yaml.dump(meta_resp, f)\n",
    "\n",
    "    with open(os.path.join(MPOSES_DIR, \"com.npy\"), \"wb\") as f:\n",
    "        coords = np.reshape(coords, (-1, meta[\"n_keypoints\"], 3))\n",
    "        com = np.mean(coords[:, com_kps2idx, :], axis=1)\n",
    "        np.save(f, com)\n",
    "\n",
    "    with open(os.path.join(MPOSES_DIR, \"joints.npy\"), \"wb\") as f:\n",
    "        np.save(f, np.array(keypoints))\n",
    "\n",
    "    with open(os.path.join(MPOSES_DIR, \"skeleton.npy\"), \"wb\") as f:\n",
    "        np.save(f, np.array(skeleton))\n",
    "\n",
    "    assert len(com) == len(coords), f\"{len(com)}, {len(coords)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization\n",
    "\n",
    "the coordinates of the poses for this dataset are not normalized and we have some huge values that lead to numerical issues. to fix this problem, i load all the poses used for training from all the sessions and then extract the min and max values of each session. once i have these values, i compute the median for the max, the median for the min and save this as meta information to normalize the poses when i'm loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normalization_factor(sessions):\n",
    "    all_max, all_min = [], []\n",
    "\n",
    "    for session in sorted(sessions):\n",
    "        POSES_DIR = os.path.join(session, \"poses\")\n",
    "        TRIALS_DIR = os.path.join(session, \"trials\")\n",
    "\n",
    "        poses_meta = yaml.safe_load(open(os.path.join(POSES_DIR, \"meta.yml\")))\n",
    "        coords = np.memmap(\n",
    "            os.path.join(POSES_DIR, \"data.mem\"),\n",
    "            dtype=poses_meta[\"dtype\"],\n",
    "            mode=\"r\",\n",
    "            shape=(poses_meta[\"n_timestamps\"], poses_meta[\"n_signals\"]),\n",
    "        )\n",
    "\n",
    "        for trial in sorted(os.listdir(TRIALS_DIR)):\n",
    "            trial_info = yaml.safe_load(open(os.path.join(TRIALS_DIR, trial)))\n",
    "            if trial_info[\"tier\"] != \"train\":\n",
    "                continue\n",
    "            start = int(trial_info[\"first_frame_idx\"] // 10)\n",
    "            end = start + int(trial_info[\"num_frames\"] // 10)\n",
    "            all_max.append(np.max(coords[start:end]))\n",
    "            all_min.append(np.min(coords[start:end]))\n",
    "\n",
    "    median_max = np.median(all_max)\n",
    "    median_min = np.median(all_min)\n",
    "\n",
    "    for session in sessions:\n",
    "        MPOSES_DIR = os.path.join(session, \"poses\", \"meta\")\n",
    "        with open(os.path.join(MPOSES_DIR, \"max.npy\"), \"wb\") as f:\n",
    "            np.save(f, np.array(median_max))\n",
    "        with open(os.path.join(MPOSES_DIR, \"min.npy\"), \"wb\") as f:\n",
    "            np.save(f, np.array(median_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = [\n",
    "    \"bex_20230221\",\n",
    "    \"bex_20230222\",\n",
    "    \"bex_20230223\",\n",
    "    \"bex_20230224\",\n",
    "    \"bex_20230225\",\n",
    "    \"bex_20230226\",\n",
    "    \"jon_20230125\",\n",
    "    \"jon_20230126\",\n",
    "    \"jon_20230127\",\n",
    "    \"jon_20230130\",\n",
    "    \"jon_20230131\",\n",
    "    \"jon_20230202\",\n",
    "    \"jon_20230203\",\n",
    "    \"luk_20230126\",  # Zurna asked to ignore this session\n",
    "    \"luk_20230127\",\n",
    "    \"luk_20230130\",\n",
    "    \"luk_20230131\",\n",
    "    \"luk_20230202\",\n",
    "    \"luk_20230203\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in sessions:\n",
    "    os.makedirs(session, exist_ok=True)\n",
    "    # process_trials(session)\n",
    "    process_responses(session)\n",
    "    # process_poses(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_normalization_factor(sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for session in sessions:\n",
    "    TRIALS_DIR = os.path.join(session, \"trials\")\n",
    "    print(len(os.listdir(TRIALS_DIR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(128,)\n",
      "(8,)\n",
      "(128,)\n",
      "(6,)\n",
      "(128,)\n",
      "(6,)\n",
      "(128,)\n",
      "(6,)\n",
      "(128,)\n",
      "(8,)\n",
      "(128,)\n",
      "(12,)\n",
      "(128,)\n",
      "(10,)\n",
      "(128,)\n",
      "(9,)\n",
      "(128,)\n",
      "(17,)\n",
      "(128,)\n",
      "(13,)\n",
      "(128,)\n",
      "(0,)\n",
      "(128,)\n",
      "(6,)\n",
      "(128,)\n",
      "(18,)\n",
      "(128,)\n",
      "(10,)\n",
      "(128,)\n",
      "(20,)\n",
      "(128,)\n",
      "(17,)\n",
      "(128,)\n",
      "(17,)\n",
      "(128,)\n",
      "(15,)\n",
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "for session in sessions:\n",
    "    MRESP_DIR = os.path.join(session, \"responses\", \"meta\")\n",
    "    for filename in sorted(os.listdir(MRESP_DIR)):\n",
    "        with open(os.path.join(MRESP_DIR, filename), \"rb\") as f:\n",
    "            print(np.load(f).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "(135853, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(112657, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(175686, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(226345, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(171907, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(196826, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(203300, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(222287, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(117084, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(108728, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(180612, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(165895, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(242329, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(166605, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(195368, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(146859, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(170496, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(151799, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n",
      "()\n",
      "(109482, 3)\n",
      "(36, 2)\n",
      "()\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "for session in sessions:\n",
    "    MPOSES_DIR = os.path.join(session, \"poses\", \"meta\")\n",
    "    for filename in sorted(os.listdir(MPOSES_DIR)):\n",
    "        with open(os.path.join(MPOSES_DIR, filename), \"rb\") as f:\n",
    "            print(np.load(f).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bex_20230221 (135853, 93) (1358530, 128)\n",
      "bex_20230222 (112657, 93) (1126570, 128)\n",
      "bex_20230223 (175686, 93) (1756860, 128)\n",
      "bex_20230224 (226345, 93) (2263450, 128)\n",
      "bex_20230225 (171907, 93) (1719070, 128)\n",
      "bex_20230226 (196826, 93) (1968260, 128)\n",
      "jon_20230125 (203300, 93) (2033000, 128)\n",
      "jon_20230126 (222287, 93) (2222870, 128)\n",
      "jon_20230127 (117084, 93) (1170840, 128)\n",
      "jon_20230130 (108728, 93) (1087280, 128)\n",
      "jon_20230131 (180612, 93) (1806120, 128)\n",
      "jon_20230202 (165895, 93) (1658950, 128)\n",
      "jon_20230203 (242329, 93) (2423290, 128)\n",
      "luk_20230126 (166605, 93) (1666050, 128)\n",
      "luk_20230127 (195368, 93) (1953680, 128)\n",
      "luk_20230130 (146859, 93) (1468590, 128)\n",
      "luk_20230131 (170496, 93) (1704960, 128)\n",
      "luk_20230202 (151799, 93) (1517990, 128)\n",
      "luk_20230203 (109482, 93) (1094820, 128)\n"
     ]
    }
   ],
   "source": [
    "for session in sessions:\n",
    "    POSES_DIR = os.path.join(session, \"poses\")\n",
    "    RESP_DIR = os.path.join(session, \"responses\")\n",
    "    poses_meta = yaml.safe_load(open(os.path.join(POSES_DIR, \"meta.yml\")))\n",
    "    coords = np.memmap(\n",
    "        os.path.join(POSES_DIR, \"data.mem\"),\n",
    "        dtype=poses_meta[\"dtype\"],\n",
    "        mode=\"r\",\n",
    "        shape=(poses_meta[\"n_timestamps\"], poses_meta[\"n_signals\"]),\n",
    "    )\n",
    "    resp_meta = yaml.safe_load(open(os.path.join(RESP_DIR, \"meta.yml\")))\n",
    "    spikes = np.memmap(\n",
    "        os.path.join(RESP_DIR, \"data.mem\"),\n",
    "        dtype=resp_meta[\"dtype\"],\n",
    "        mode=\"r\",\n",
    "        shape=(\n",
    "            resp_meta[\"n_timestamps\"],\n",
    "            resp_meta[\"n_signals\"],\n",
    "        ),\n",
    "    )\n",
    "    print(session, coords.shape, spikes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to open with forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in sessions:\n",
    "    POSES_DIR = os.path.join(session, \"poses\")\n",
    "    MPOSES_DIR = os.path.join(session, \"poses\", \"meta\")\n",
    "    TRIALS_DIR = os.path.join(session, \"trials\")\n",
    "\n",
    "    poses_meta = yaml.safe_load(open(os.path.join(POSES_DIR, \"meta.yml\")))\n",
    "    coords = np.memmap(\n",
    "        os.path.join(POSES_DIR, \"data.mem\"),\n",
    "        dtype=poses_meta[\"dtype\"],\n",
    "        mode=\"r\",\n",
    "        shape=(poses_meta[\"n_timestamps\"], poses_meta[\"n_signals\"]),\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(MPOSES_DIR, \"skeleton.npy\"), \"rb\") as f:\n",
    "        skeleton = np.load(f)\n",
    "\n",
    "    for i, trial in enumerate(sorted(os.listdir(TRIALS_DIR))):\n",
    "        with open(os.path.join(TRIALS_DIR, trial), \"r\") as f:\n",
    "            trial_info = yaml.safe_load(f)\n",
    "            trial_start = int(trial_info[\"first_frame_idx\"] // 10)\n",
    "            trial_end = int(\n",
    "                (trial_info[\"first_frame_idx\"] + trial_info[\"num_frames\"]) // 10\n",
    "            )\n",
    "\n",
    "        with open(os.path.join(\"forge\", f\"{session}_trial_{i}.pkl\"), \"wb\") as f:\n",
    "            poses = coords[trial_start:trial_end]\n",
    "            poses = poses.reshape(-1, 31, 3).copy()\n",
    "            poses[..., [1, 2]] = poses[..., [2, 1]]\n",
    "            data = {\n",
    "                \"sequence\": poses,\n",
    "                \"skeleton\": skeleton,\n",
    "                \"frametime\": 1000 // poses_meta[\"sampling_rate\"],\n",
    "            }\n",
    "            pickle.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
