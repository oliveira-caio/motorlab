{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sessions\n",
    "- each session is a different dataset\n",
    "- folders inside each session: responses, poses, reward and trials\n",
    "- trials is not a modality, it's just for me to keep track of information when evaluating the model\n",
    "\n",
    "### poses\n",
    "- `data.mem`: $(x, y, z)$ coordinates of each joint for the full session. shape: `(n_frames, 3*n_joints)`\n",
    "- `meta.yml`: dictionary with metadata, see `metadata` below\n",
    "- `meta/com.npy`: $(x, y, z)$ coordinate of the center of mass (com) for the full session. shape: `(n_frames, 3)`\n",
    "- `meta/joints.npy`: name of the joints tracked\n",
    "- `meta/skeleton.npy`: adjacency list for all the joints\n",
    "\n",
    "### responses\n",
    "- `data.mem`: timing of each spike of each neuron for the full session. shape: `(n_frames, n_neurons)`\n",
    "- `meta.yml`: dictionary with metadata, see `metadata` below\n",
    "- `meta/areas.npy`: array with the brain areas\n",
    "\n",
    "### target\n",
    "- `data.mem`: something like a np.array with the target information for each frame. 0 before the cue is shown, 1 after the cue was showed if it indicates left and 2 if it indicates right. shape: `(n_frames, 1)`\n",
    "- `meta.yml`: dictionary with metadata, see `metadata` below\n",
    "\n",
    "### metadata (meta.yml files)\n",
    "- `dtype`: necessary to load `.mem` files\n",
    "- `is_mem_mapped`: if it's `.mem` or `.npy`\n",
    "- `modality`: sequence or trial\n",
    "- `n_signals`: number of joints, neurons etc\n",
    "- `n_timestamps`: number of frames \n",
    "- `phase_shift_per_signal`: useless for me, always false\n",
    "- `sampling_rate`: 100 for poses, 1000 for responses, target and trials\n",
    "- `start_time`: 0 in my case, i think\n",
    "\n",
    "### trials\n",
    "- trial_start: when each trial starts\n",
    "- trial_end: when each trial ends\n",
    "- toc (time of commitment): when the monkey committed to a target\n",
    "- trial_type: precue, gbyk, feedback\n",
    "- walk_start: when the monkey starts walking\n",
    "- walk_end: when the monkey stops walking\n",
    "- cue_start: time of the signal that shows the reward\n",
    "- cue_end: end of the signal\n",
    "- choice: L, R\n",
    "- reward: L, R (can be different from choice if the monkey ignores the highest reward)\n",
    "\n",
    "##### to keep in mind\n",
    "- figure out how to parse the toc\n",
    "- how walk_start and walk_end are represented? relative to trial start?\n",
    "- how is walk_start/mt_on and walk_end/mt_off encoded?\n",
    "- for ken_20230618, some trials are off by one, which gives nan for coords. should be fixed when we have data for the full session.\n",
    "- if we don't know when the cue is showed for \"precue\" trials, how should we define the target? or is it the case that the trial start time in this case is the time when the cue is showed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_strings(references, file):\n",
    "    return [\"\".join((chr(x[0]) for x in file[ref[0]])) for ref in references]\n",
    "\n",
    "\n",
    "old_keypoints = [\n",
    "    \"L_wrist\",\n",
    "    \"L_elbow\",\n",
    "    \"L_shoulder\",\n",
    "    \"R_wrist\",\n",
    "    \"R_elbow\",\n",
    "    \"R_shoulder\",\n",
    "    \"L_ankle\",\n",
    "    \"L_knee\",\n",
    "    \"L_hip\",\n",
    "    \"R_ankle\",\n",
    "    \"R_knee\",\n",
    "    \"R_hip\",\n",
    "    \"E_tail\",\n",
    "    \"S_tail\",\n",
    "    \"neck\",\n",
    "    \"head\",\n",
    "    \"L_ear\",\n",
    "    \"R_ear\",\n",
    "    \"L_eye\",\n",
    "    \"R_eye\",\n",
    "    \"nose\",\n",
    "]\n",
    "\n",
    "old_skeleton = [\n",
    "    [1, 0],\n",
    "    [1, 2],\n",
    "    [4, 3],\n",
    "    [4, 5],\n",
    "    [7, 6],\n",
    "    [7, 8],\n",
    "    [10, 9],\n",
    "    [10, 11],\n",
    "    [13, 8],\n",
    "    [13, 11],\n",
    "    [13, 12],\n",
    "    [14, 2],\n",
    "    [14, 5],\n",
    "    [14, 13],\n",
    "    [14, 15],\n",
    "    [14, 16],\n",
    "    [14, 17],\n",
    "    [14, 20],\n",
    "    [15, 16],\n",
    "    [15, 17],\n",
    "    [15, 18],\n",
    "    [15, 19],\n",
    "    [20, 16],\n",
    "    [20, 17],\n",
    "    [20, 18],\n",
    "    [20, 19],\n",
    "]\n",
    "\n",
    "new_keypoints = [\n",
    "    \"E_tail\",\n",
    "    \"L_ankle\",\n",
    "    \"L_ear\",\n",
    "    \"L_elbow\",\n",
    "    \"L_eye\",\n",
    "    \"L_hip\",\n",
    "    \"L_knee\",\n",
    "    \"L_shoulder\",\n",
    "    \"L_wrist\",\n",
    "    \"R_ankle\",\n",
    "    \"R_ear\",\n",
    "    \"R_elbow\",\n",
    "    \"R_eye\",\n",
    "    \"R_hip\",\n",
    "    \"R_knee\",\n",
    "    \"R_shoulder\",\n",
    "    \"R_wrist\",\n",
    "    \"S_tail\",\n",
    "    \"head\",\n",
    "    \"neck\",\n",
    "    \"nose\",\n",
    "]\n",
    "new_skeleton = [\n",
    "    [3, 7],\n",
    "    [3, 8],\n",
    "    [6, 1],\n",
    "    [6, 5],\n",
    "    [11, 15],\n",
    "    [11, 16],\n",
    "    [14, 9],\n",
    "    [14, 13],\n",
    "    [17, 0],\n",
    "    [17, 5],\n",
    "    [17, 13],\n",
    "    [18, 2],\n",
    "    [18, 4],\n",
    "    [18, 10],\n",
    "    [18, 12],\n",
    "    [19, 2],\n",
    "    [19, 7],\n",
    "    [19, 10],\n",
    "    [19, 15],\n",
    "    [19, 17],\n",
    "    [19, 18],\n",
    "    [19, 20],\n",
    "    [20, 2],\n",
    "    [20, 4],\n",
    "    [20, 10],\n",
    "    [20, 12],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trials(SESSION_DIR: Path) -> None:\n",
    "    TRIALS_DIR = SESSION_DIR / \"trials\"\n",
    "    TRIALS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    filename = SESSION_DIR.name\n",
    "    trials_info = pd.read_csv(f\"../data/gbyk/{filename}.csv\")\n",
    "    success_idxs = trials_info[trials_info[\"outcome\"] == \"success\"].index\n",
    "\n",
    "    with h5py.File(f\"../data/gbyk/{filename}.mat\") as dataset:\n",
    "        trials_start = dataset[\"spikes\"][\"trial_start\"][:][0][success_idxs]\n",
    "        trials_end = dataset[\"spikes\"][\"trial_end\"][:][0][success_idxs]\n",
    "\n",
    "    random.seed(0)\n",
    "    train_idxs = list(range(len(success_idxs)))\n",
    "    test_size = int(len(train_idxs) * 0.2)\n",
    "    val_size = int(len(train_idxs) * 0.2)\n",
    "    test_idxs = random.sample(train_idxs, test_size)\n",
    "    remaining_idxs = sorted(list(set(train_idxs) - set(test_idxs)))\n",
    "    val_idxs = random.sample(remaining_idxs, val_size)\n",
    "    tiers = {\"train\": train_idxs, \"validation\": val_idxs, \"test\": test_idxs}\n",
    "\n",
    "    trials_info.columns = trials_info.columns.map(str.lower)\n",
    "    trials_info = trials_info[trials_info[\"outcome\"] == \"success\"].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    assert len(trials_info) == len(trials_start)\n",
    "    assert len(trials_info) == len(trials_end)\n",
    "\n",
    "    trials_info[\"reward\"] = np.where(\n",
    "        trials_info[\"reward\"] == 1.8,\n",
    "        trials_info[\"choice\"],\n",
    "        trials_info[\"choice\"].map({\"L\": \"R\", \"R\": \"L\"}),\n",
    "    )\n",
    "    trials_info[\"cue\"] = np.where(\n",
    "        trials_info[\"block\"] == \"precue\",\n",
    "        trials_info[\"precue_abstime\"],  # Condition 1\n",
    "        np.where(\n",
    "            trials_info[\"block\"] == \"gbyk\",\n",
    "            (trials_info[\"cuestart_abstime\"] + trials_info[\"cueend_abstime\"])\n",
    "            / 2,  # Condition 2\n",
    "            trials_end,  # Condition 3 (feedback)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    for tier in tiers:\n",
    "        for idx in tiers[tier]:\n",
    "            with open(TRIALS_DIR / f\"{idx:05d}.yml\", \"w\") as f:\n",
    "                data = {\n",
    "                    \"choice\": trials_info.loc[idx, \"choice\"],\n",
    "                    \"cue_frame_idx\": int(trials_info.loc[idx, \"cue\"].item()),\n",
    "                    \"first_frame_idx\": int(trials_start[idx].item()),\n",
    "                    \"num_frames\": int(\n",
    "                        (trials_end[idx] - trials_start[idx]).item()\n",
    "                    ),\n",
    "                    # \"walk_start\": trials_info.loc[idx, \"walk_start\"],\n",
    "                    # \"walk_end\": trials_info.loc[idx, \"walk_end\"],\n",
    "                    \"reward\": trials_info.loc[idx, \"reward\"],\n",
    "                    \"tier\": tier,\n",
    "                    \"trial_idx\": idx,\n",
    "                    \"type\": trials_info.loc[idx, \"block\"],\n",
    "                }\n",
    "                yaml.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_spikes(SESSION_DIR: Path) -> None:\n",
    "    SPIKES_DIR = SESSION_DIR / \"spikes\"\n",
    "    SPIKES_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    META_SPIKES_DIR = SPIKES_DIR / \"meta\"\n",
    "    META_SPIKES_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    filename = SESSION_DIR.name\n",
    "    dataset = h5py.File(f\"../data/gbyk/{filename}.mat\")\n",
    "\n",
    "    ### responses\n",
    "    spikes = dataset[\"spikes\"][\"session\"][:]\n",
    "    mmap = np.memmap(\n",
    "        SPIKES_DIR / \"data.mem\",\n",
    "        dtype=\"float32\",\n",
    "        mode=\"w+\",\n",
    "        shape=spikes.shape,\n",
    "    )\n",
    "    mmap[:] = spikes[:]\n",
    "    mmap.flush()\n",
    "\n",
    "    ### meta\n",
    "    with open(SPIKES_DIR / \"meta.yml\", \"w\") as f:\n",
    "        meta = {\n",
    "            \"dtype\": \"float32\",\n",
    "            \"end_time\": len(spikes),\n",
    "            \"is_mem_mapped\": True,\n",
    "            \"modality\": \"sequence\",\n",
    "            \"n_signals\": spikes.shape[-1],\n",
    "            \"n_timestamps\": len(spikes),\n",
    "            \"phase_shift_per_signal\": False,\n",
    "            \"sampling_rate\": 1000,\n",
    "            \"start_time\": 0,\n",
    "        }\n",
    "        yaml.dump(meta, f)\n",
    "\n",
    "    with open(META_SPIKES_DIR / \"areas.npy\", \"wb\") as f:\n",
    "        areas = np.array(\n",
    "            extract_strings(dataset[\"spikes\"][\"array_labels\"], dataset)\n",
    "        )\n",
    "        array_code = dataset[\"spikes\"][\"array_code\"][:].ravel() - 1  # 1-based\n",
    "        np.save(f, areas[array_code.astype(int)])\n",
    "\n",
    "    assert len(array_code) == spikes.shape[-1], (\n",
    "        f\"{len(array_code)}, {spikes.shape[-1]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process spike count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_spike_count(SESSION_DIR: Path, sampling_rate: int = 20) -> None:\n",
    "    SPIKE_COUNT_DIR = SESSION_DIR / \"spike_count\"\n",
    "    SPIKE_COUNT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    META_SPIKE_COUNT_DIR = SPIKE_COUNT_DIR / \"meta\"\n",
    "    META_SPIKE_COUNT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    SPIKES_DIR = SESSION_DIR / \"spikes\"\n",
    "    period = int(1000 / sampling_rate)\n",
    "\n",
    "    with open(SPIKES_DIR / \"meta.yml\", \"r\") as f:\n",
    "        meta = yaml.safe_load(f)\n",
    "        spikes = np.memmap(\n",
    "            SPIKES_DIR / \"data.mem\",\n",
    "            dtype=meta[\"dtype\"],\n",
    "            mode=\"r\",\n",
    "            shape=(meta[\"n_timestamps\"], meta[\"n_signals\"]),\n",
    "        )\n",
    "\n",
    "    duration = len(spikes) - (len(spikes) % period)\n",
    "    spike_count = (\n",
    "        spikes[:duration].reshape(len(spikes) // period, period, -1).sum(axis=1)\n",
    "    )\n",
    "\n",
    "    mmap = np.memmap(\n",
    "        SPIKE_COUNT_DIR / \"data.mem\",\n",
    "        dtype=\"float32\",\n",
    "        mode=\"w+\",\n",
    "        shape=spike_count.shape,\n",
    "    )\n",
    "    mmap[:] = spike_count[:]\n",
    "    mmap.flush()\n",
    "\n",
    "    with open(SPIKE_COUNT_DIR / \"meta.yml\", \"w\") as f:\n",
    "        meta = {\n",
    "            \"dtype\": \"float32\",\n",
    "            \"end_time\": len(spike_count),\n",
    "            \"is_mem_mapped\": True,\n",
    "            \"modality\": \"sequence\",\n",
    "            \"n_signals\": spike_count.shape[-1],\n",
    "            \"n_timestamps\": len(spike_count),\n",
    "            \"phase_shift_per_signal\": False,\n",
    "            \"sampling_rate\": sampling_rate,\n",
    "            \"start_time\": 0,\n",
    "        }\n",
    "        yaml.dump(meta, f)\n",
    "\n",
    "    shutil.copytree(\n",
    "        SPIKES_DIR / \"meta\", META_SPIKE_COUNT_DIR, dirs_exist_ok=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_poses(SESSION_DIR: Path, old_format: bool = False) -> None:\n",
    "    POSES_DIR = SESSION_DIR / \"poses\"\n",
    "    POSES_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    META_POSES_DIR = POSES_DIR / \"meta\"\n",
    "    META_POSES_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    file_name = SESSION_DIR.name\n",
    "    file_path = Path(f\"../data/gbyk/{file_name}.mat\")\n",
    "    dataset = h5py.File(file_path)\n",
    "\n",
    "    ### center of mass\n",
    "    with open(META_POSES_DIR / \"com.npy\", \"wb\") as f:\n",
    "        x_com = dataset[\"spikes\"][\"Traj\"][\"x\"][0]\n",
    "        y_com = dataset[\"spikes\"][\"Traj\"][\"y\"][0]\n",
    "        z_com = dataset[\"spikes\"][\"Traj\"][\"z\"][0]\n",
    "        com = np.stack([x_com, y_com, z_com], axis=0).T\n",
    "        np.save(f, com)\n",
    "\n",
    "    ### coords\n",
    "    # first five joints are useless for the denoised datasets\n",
    "    if old_format:\n",
    "        x_coords = dataset[\"spikes\"][\"Body\"][\"x\"][5:]\n",
    "        y_coords = dataset[\"spikes\"][\"Body\"][\"y\"][5:]\n",
    "        z_coords = dataset[\"spikes\"][\"Body\"][\"z\"][5:]\n",
    "    else:\n",
    "        x_coords = dataset[\"spikes\"][\"Body\"][\"x\"]\n",
    "        y_coords = dataset[\"spikes\"][\"Body\"][\"y\"]\n",
    "        z_coords = dataset[\"spikes\"][\"Body\"][\"z\"]\n",
    "\n",
    "    # after next line the shape is (n_joints, 3, n_frames)\n",
    "    coords = np.stack([x_coords, y_coords, z_coords], axis=1)\n",
    "    coords = np.reshape(coords, (-1, coords.shape[-1])).T\n",
    "    mmap = np.memmap(\n",
    "        os.path.join(POSES_DIR, \"data.mem\"),\n",
    "        dtype=\"float32\",\n",
    "        mode=\"w+\",\n",
    "        shape=coords.shape,\n",
    "    )\n",
    "    mmap[:] = coords\n",
    "    mmap.flush()\n",
    "\n",
    "    ### meta\n",
    "    with open(POSES_DIR / \"meta.yml\", \"w\") as f:\n",
    "        meta = {\n",
    "            \"dtype\": \"float32\",\n",
    "            \"end_time\": len(coords),\n",
    "            \"is_mem_mapped\": True,\n",
    "            \"modality\": \"sequence\",\n",
    "            \"n_signals\": coords.shape[-1],\n",
    "            \"n_timestamps\": len(coords),\n",
    "            \"phase_shift_per_signal\": False,\n",
    "            \"sampling_rate\": 100,\n",
    "            \"start_time\": 0,\n",
    "        }\n",
    "        yaml.dump(meta, f)\n",
    "\n",
    "    with open(META_POSES_DIR / \"joints.npy\", \"wb\") as f:\n",
    "        if old_format:\n",
    "            np.save(f, np.array(old_keypoints))\n",
    "        else:\n",
    "            np.save(f, np.array(new_keypoints))\n",
    "\n",
    "    with open(META_POSES_DIR / \"skeleton.npy\", \"wb\") as f:\n",
    "        if old_format:\n",
    "            np.save(f, np.array(old_skeleton))\n",
    "        else:\n",
    "            np.save(f, np.array(new_skeleton))\n",
    "\n",
    "    assert len(com) == len(coords), f\"{len(com)}, {len(coords)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_target(SESSION_DIR: Path) -> None:\n",
    "    TARGET_DIR = SESSION_DIR / \"target\"\n",
    "    TARGET_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    with open(SESSION_DIR / \"spikes/meta.yml\", \"r\") as f:\n",
    "        meta_responses = yaml.safe_load(f)\n",
    "        target = np.zeros(meta_responses[\"n_timestamps\"])\n",
    "\n",
    "    TRIALS_DIR = SESSION_DIR / \"trials\"\n",
    "    for trial in TRIALS_DIR.iterdir():\n",
    "        with open(trial, \"r\") as f:\n",
    "            trial_info = yaml.safe_load(f)\n",
    "            cue_idx = trial_info[\"cue_frame_idx\"]\n",
    "            end_idx = trial_info[\"first_frame_idx\"] + trial_info[\"num_frames\"]\n",
    "            target[cue_idx:end_idx] = 1 if trial_info[\"reward\"] == \"R\" else 2\n",
    "\n",
    "    mmap = np.memmap(\n",
    "        TARGET_DIR / \"data.mem\",\n",
    "        dtype=\"float32\",\n",
    "        mode=\"w+\",\n",
    "        shape=target.shape,\n",
    "    )\n",
    "    mmap[:] = target[:]\n",
    "    mmap.flush()\n",
    "\n",
    "    ### meta\n",
    "    with open(TARGET_DIR / \"meta.yml\", \"w\") as f:\n",
    "        meta = {\n",
    "            \"dtype\": \"float32\",\n",
    "            \"end_time\": len(target),\n",
    "            \"is_mem_mapped\": True,\n",
    "            \"modality\": \"sequence\",\n",
    "            \"n_signals\": target.shape[-1] if len(target.shape) > 1 else 1,\n",
    "            \"n_timestamps\": len(target),\n",
    "            \"phase_shift_per_signal\": False,\n",
    "            \"sampling_rate\": 1000,\n",
    "            \"start_time\": 0,\n",
    "        }\n",
    "        yaml.dump(meta, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = [\n",
    "    \"bex_20230623_denoised\",\n",
    "    \"ken_20230614_denoised\",\n",
    "    \"ken_20230618_denoised\",\n",
    "]\n",
    "old_format = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = [\n",
    "    \"bex_20230621_spikes_sorted_SES\",\n",
    "    \"bex_20230624_spikes_sorted_SES\",\n",
    "    \"bex_20230629_spikes_sorted_SES\",\n",
    "    \"bex_20230630_spikes_sorted_SES\",\n",
    "    \"bex_20230701_spikes_sorted_SES\",\n",
    "    \"bex_20230708_spikes_sorted_SES\",\n",
    "    # \"ken_20230614_spikes_sorted_SES\",\n",
    "    \"ken_20230618_spikes_sorted_SES\",\n",
    "    \"ken_20230622_spikes_sorted_SES\",\n",
    "    \"ken_20230629_spikes_sorted_SES\",\n",
    "    \"ken_20230630_spikes_sorted_SES\",\n",
    "    \"ken_20230701_spikes_sorted_SES\",\n",
    "    \"ken_20230703_spikes_sorted_SES\",\n",
    "]\n",
    "old_format = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in sessions:\n",
    "    SESSION_DIR = Path(f\"../data/gbyk/{session}\")\n",
    "    SESSION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    process_trials(SESSION_DIR)\n",
    "    process_spikes(SESSION_DIR)\n",
    "    process_spike_count(SESSION_DIR)\n",
    "    process_poses(SESSION_DIR, old_format)\n",
    "    process_target(SESSION_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in sessions:\n",
    "    TRIALS_DIR = os.path.join(session, \"trials\")\n",
    "    print(len(os.listdir(TRIALS_DIR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in sessions:\n",
    "    META_SPIKE_COUNT_DIR = os.path.join(session, \"responses\", \"meta\")\n",
    "    for filename in os.listdir(META_SPIKE_COUNT_DIR):\n",
    "        with open(os.path.join(META_SPIKE_COUNT_DIR, filename), \"rb\") as f:\n",
    "            print(np.load(f).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in sessions:\n",
    "    META_POSES_DIR = os.path.join(session, \"poses\", \"meta\")\n",
    "    for filename in os.listdir(META_POSES_DIR):\n",
    "        with open(os.path.join(META_POSES_DIR, filename), \"rb\") as f:\n",
    "            print(np.load(f).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in sessions:\n",
    "    POSES_DIR = os.path.join(session, \"poses\")\n",
    "    SPIKES_DIR = os.path.join(session, \"responses\")\n",
    "    poses_meta = yaml.safe_load(open(os.path.join(POSES_DIR, \"meta.yml\")))\n",
    "    resp_meta = yaml.safe_load(open(os.path.join(SPIKES_DIR, \"meta.yml\")))\n",
    "    coords = np.memmap(\n",
    "        os.path.join(POSES_DIR, \"data.mem\"),\n",
    "        dtype=poses_meta[\"dtype\"],\n",
    "        mode=\"r\",\n",
    "        shape=(poses_meta[\"n_timestamps\"], poses_meta[\"n_signals\"]),\n",
    "    )\n",
    "    spikes = np.memmap(\n",
    "        os.path.join(SPIKES_DIR, \"data.mem\"),\n",
    "        dtype=resp_meta[\"dtype\"],\n",
    "        mode=\"r\",\n",
    "        shape=(\n",
    "            resp_meta[\"n_timestamps\"],\n",
    "            resp_meta[\"n_signals\"],\n",
    "        ),\n",
    "    )\n",
    "    print(coords.shape, spikes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = coords.reshape(-1, 21, 3)\n",
    "print(coords[..., 1].max(), coords[..., 1].min())\n",
    "print(coords[..., 0].max(), coords[..., 0].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to open with forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in sessions:\n",
    "    POSES_DIR = os.path.join(session, \"poses\")\n",
    "    META_POSES_DIR = os.path.join(session, \"poses\", \"meta\")\n",
    "    TRIALS_DIR = os.path.join(session, \"trials\")\n",
    "\n",
    "    poses_meta = yaml.safe_load(open(os.path.join(POSES_DIR, \"meta.yml\")))\n",
    "    coords = np.memmap(\n",
    "        os.path.join(POSES_DIR, \"data.mem\"),\n",
    "        dtype=poses_meta[\"dtype\"],\n",
    "        mode=\"r\",\n",
    "        shape=(poses_meta[\"n_timestamps\"], poses_meta[\"n_signals\"]),\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(META_POSES_DIR, \"skeleton.npy\"), \"rb\") as f:\n",
    "        skeleton = np.load(f)\n",
    "\n",
    "    for i, trial in enumerate(sorted(os.listdir(TRIALS_DIR))):\n",
    "        with open(os.path.join(TRIALS_DIR, trial), \"r\") as f:\n",
    "            trial_info = yaml.safe_load(f)\n",
    "            trial_start = int(trial_info[\"first_frame_idx\"] // 10)\n",
    "            trial_end = int(\n",
    "                (trial_info[\"first_frame_idx\"] + trial_info[\"num_frames\"]) // 10\n",
    "            )\n",
    "\n",
    "        with open(os.path.join(\"forge\", f\"{session}_trial_{i}.pkl\"), \"wb\") as f:\n",
    "            poses = coords[trial_start:trial_end] / 4.325\n",
    "            poses = poses.reshape(-1, 21, 3).copy()\n",
    "            poses[..., [1, 2]] = poses[..., [2, 1]]\n",
    "            poses[..., [0]] = -poses[..., [0]] + 0.3\n",
    "            poses[..., [1]] = poses[..., [1]] - 0.05\n",
    "            data = {\n",
    "                \"sequence\": poses,\n",
    "                \"skeleton\": skeleton,\n",
    "                \"frametime\": 1000 // poses_meta[\"sampling_rate\"],\n",
    "            }\n",
    "            pickle.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
