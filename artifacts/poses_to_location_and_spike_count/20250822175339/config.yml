artifacts_dir: artifacts/
data:
  dataloader:
    batch_size: 64
    max_length: 80
    min_length: 80
  dataset:
    concat_input: true
    concat_output: false
    input_dims:
      bex_20230623_denoised:
        poses: 63
      ken_20230614_denoised:
        poses: 63
      ken_20230618_denoised:
        poses: 63
    input_modalities:
    - poses
    output_dims:
      bex_20230623_denoised:
        location: 2
        spike_count: 97
      ken_20230614_denoised:
        location: 2
        spike_count: 243
      ken_20230618_denoised:
        location: 2
        spike_count: 244
    output_modalities:
    - spike_count
    - location
    stride: 20
  dir: data
  intervals:
    balance_intervals: false
    include_homing: true
    include_sitting: true
    include_trial: true
  modalities:
    kinematics:
      representation: com_vec
    location:
      representation: com
    poses:
      coordinates: egocentric
      representation: adversarial
      skeleton_type: normal
    spike_count:
      brain_areas: all
    spikes:
      brain_areas: all
  sampling_rate: 20
experiment: old_gbyk
logger:
  dir: artifacts/poses_to_location_and_spike_count/20250822175339
  plots: false
model:
  architecture: embedding_core_readout
  core:
    architecture: gru
    dropout: 0.1
    hidden_dim: 256
    in_dim: 256
    n_layers: 1
  embedding:
    architecture:
      bex_20230623_denoised:
        poses: linear
      ken_20230614_denoised:
        poses: linear
      ken_20230618_denoised:
        poses: linear
    dim: 256
  readout:
    map:
      bex_20230623_denoised:
        location: identity
        spike_count: softplus
      ken_20230614_denoised:
        location: identity
        spike_count: softplus
      ken_20230618_denoised:
        location: identity
        spike_count: softplus
save: true
seed: 0
sessions:
- bex_20230623_denoised
- ken_20230614_denoised
- ken_20230618_denoised
task: poses_to_location_and_spike_count
trainer:
  early_stopper:
    enabled: true
    metric: val_local_corr
    minimize: false
    patience: 10
  loss_fns:
    names:
      location: closed_mse
      spike_count: poisson
    weights:
      location: -0.05037565750518596
      spike_count: 1.0
  max_epochs: 100
  metrics:
    spike_count: correlation
  optimizer:
    algorithm: adam
    lr: 0.003
    weight_decay: 1.0e-05
  scheduler:
    T_max: 100
    eta_min: 0.0001
    method: cosine_annealing
  validation_frequency: 25
uid: '20250822175339'
